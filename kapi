#!/usr/bin/env bash

# Simple framework for calling Khoros APIs. The way this works is that
# files are created, for cacheing and step purposes. 
#
# All API URLs requested are logged in a file for manual use if 
# required.
#
# Any dataset retrieved via an API call is saved in a corresponding
# JSON file, named after the function used to retrieve that dataset,
# for example upcoming_codejams.json and rsvps.json. This is so the
# data can be queried ad hoc after the script has finished. Note that
# new executions of this script will overwrite existing file content.
#
# Also, this script will save to a file, based on this script's name
# (i.e. kapi.json) the final JSON dataset, as well as emitting it to
# STDOUT.

set -eo pipefail

source "$(dirname "$0")/lib.sh"

# Utility functions -------------------------------------------------

makerequest() {

  local url="${1:?Specify URL}"

  curl \
    --fail \
    --silent \
    --url "$url"

  log "$url"

}

search() {

  # Makes LiQL query via the 'search' API endpoint, and also
  # saves the result in a file named after the caller function.

  local caller
  caller="${FUNCNAME[1]}"

  local query="${1:?Specify LiQL query}"
  makerequest "$baseurl/search?q=$(urlenc "$query")" \
    | tee "$caller.json"

}

# Specific API request functions ------------------------------------

upcoming_codejams() {

  search "$(cat << EOF | tr '\n' ' '
select *
from messages
where board.id = 'codejam-events'
and occasion_data.start_time > $nowepochms
and depth = 0
order by occasion_data.start_time
EOF
  )"

}

rsvps() {

  local eventids="$1"

  search "$(cat << EOF | tr '\n' ' '
select *
from rsvps
where message.id in ($eventids)
limit 1000
EOF
  )"

}

# Everything starts here --------------------------------------------

start() {

  local ids

  # Clean up any old dataset files and log file
  rm -f "$scriptname.log" rsvps.json upcoming_codejams.json

  # Retrieve upcoming CodeJams and then gather their event IDs for
  # use in a subsequent query, like this: '1', '2', '3' etc.
  ids="$(
    jq -r '[.data.items[].id]|@csv' <(upcoming_codejams) \
    | tr '"' "'"
  )"

  # Now use those IDs in a query for RSVP data (and redirect output
  # to /dev/null as we don't need to use it here; a dataset called
  # rsvps.json has been saved implicitly).
  rsvps "$ids" > /dev/null

  # Check we have the two dataset files (implicitly via the tee call
  # in the search function) before proceeding.
  [ ! -f rsvps.json ] || [ ! -f upcoming_codejams.json ] \
    && die "Datasets not available"

  # Now we have CodeJam and RSVP datasets, we can merge them.
  jq \
    --slurp \
    --from-file merge-codejams-rsvps.jq \
    rsvps.json upcoming_codejams.json \
    | tee "$scriptname.json"

}

liql() {

  search "$*" | jq .

}


main() {

  # Assume we are given an LiQL expression if there are any args
  if [[ $# -gt 0 ]]; then
    liql "$@"
  else
    start
  fi

}


main "$@"
